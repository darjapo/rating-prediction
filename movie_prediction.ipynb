{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B8ZBySLZO65"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "uoXyvmcKZSQP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKMbWs1qAkzy"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QiAYk1MOAkz1"
      },
      "outputs": [],
      "source": [
        "ratings_train = pd.read_csv('ratings_train.csv')\n",
        "ratings_valid = pd.read_csv('ratings_valid.csv')\n",
        "movies = pd.read_csv('movies.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5FG_-jei--x"
      },
      "source": [
        "# Cosine similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qe8_JsbY8gh"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04ChzYoajOOr",
        "outputId": "86b036e8-a0c5-467d-b45e-861e2ef5ad04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movieId  1       2       3       4       5       6       7       8       \\\n",
            "userId                                                                    \n",
            "1           4.0     0.0     4.0     0.0     0.0     4.0     0.0     0.0   \n",
            "2           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "3           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "4           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "5           4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "\n",
            "movieId  9       10      ...  193565  193567  193571  193573  193579  193581  \\\n",
            "userId                   ...                                                   \n",
            "1           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "2           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "3           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "4           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "5           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "\n",
            "movieId  193583  193585  193587  193609  \n",
            "userId                                   \n",
            "1           0.0     0.0     0.0     0.0  \n",
            "2           0.0     0.0     0.0     0.0  \n",
            "3           0.0     0.0     0.0     0.0  \n",
            "4           0.0     0.0     0.0     0.0  \n",
            "5           0.0     0.0     0.0     0.0  \n",
            "\n",
            "[5 rows x 9690 columns]\n"
          ]
        }
      ],
      "source": [
        "# Construct the user-item matrix from training data\n",
        "# Pivot the training dataset to create a matrix with users as rows, movies as columns, and ratings as values\n",
        "# Fill missing ratings with 0 to indicate unrated movies\n",
        "utility_matrix = ratings_train.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "\n",
        "# Display the first few rows of the utility matrix to verify its structure\n",
        "print(utility_matrix.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_czqNN4RwLGj"
      },
      "source": [
        "## Create cosine similarity matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ualDoP0fIx9Z",
        "outputId": "61afebc1-21f3-40d0-89a0-4b777e16eb1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "userId       1         2         3         4         5         6         7    \\\n",
            "userId                                                                         \n",
            "1       1.000000  0.027283  0.059720  0.210282  0.129080  0.128152  0.158744   \n",
            "2       0.027283  1.000000  0.000000  0.004167  0.016614  0.025333  0.027585   \n",
            "3       0.059720  0.000000  1.000000  0.002518  0.005020  0.003936  0.000000   \n",
            "4       0.210282  0.004167  0.002518  1.000000  0.107718  0.085415  0.117554   \n",
            "5       0.129080  0.016614  0.005020  0.107718  1.000000  0.300349  0.108342   \n",
            "...          ...       ...       ...       ...       ...       ...       ...   \n",
            "606     0.164191  0.028429  0.012993  0.184199  0.106435  0.102123  0.200035   \n",
            "607     0.269389  0.012948  0.019247  0.136068  0.152866  0.162182  0.186114   \n",
            "608     0.291097  0.046211  0.021128  0.163608  0.135535  0.178809  0.323541   \n",
            "609     0.093572  0.027565  0.000000  0.024007  0.261232  0.214234  0.090840   \n",
            "610     0.145321  0.102427  0.032119  0.103752  0.060792  0.052668  0.193219   \n",
            "\n",
            "userId       8         9         10   ...       601       602       603  \\\n",
            "userId                                ...                                 \n",
            "1       0.136968  0.064263  0.018329  ...  0.081481  0.164455  0.221486   \n",
            "2       0.027257  0.000000  0.073255  ...  0.205005  0.016866  0.011997   \n",
            "3       0.004941  0.000000  0.000000  ...  0.005106  0.004892  0.024992   \n",
            "4       0.070424  0.012706  0.031502  ...  0.097220  0.129750  0.272360   \n",
            "5       0.429075  0.000000  0.033248  ...  0.068831  0.418747  0.110148   \n",
            "...          ...       ...       ...  ...       ...       ...       ...   \n",
            "606     0.099388  0.075898  0.084767  ...  0.180134  0.116534  0.300669   \n",
            "607     0.185142  0.011844  0.011351  ...  0.093590  0.199910  0.203540   \n",
            "608     0.187233  0.100435  0.084093  ...  0.160178  0.197514  0.232771   \n",
            "609     0.423993  0.000000  0.023641  ...  0.036063  0.335231  0.061941   \n",
            "610     0.078153  0.074399  0.117078  ...  0.225053  0.087528  0.163094   \n",
            "\n",
            "userId       604       605       606       607       608       609       610  \n",
            "userId                                                                        \n",
            "1       0.070669  0.153625  0.164191  0.269389  0.291097  0.093572  0.145321  \n",
            "2       0.000000  0.000000  0.028429  0.012948  0.046211  0.027565  0.102427  \n",
            "3       0.000000  0.010694  0.012993  0.019247  0.021128  0.000000  0.032119  \n",
            "4       0.047971  0.094598  0.184199  0.136068  0.163608  0.024007  0.103752  \n",
            "5       0.258773  0.148758  0.106435  0.152866  0.135535  0.261232  0.060792  \n",
            "...          ...       ...       ...       ...       ...       ...       ...  \n",
            "606     0.066032  0.148141  1.000000  0.153063  0.262558  0.069622  0.201104  \n",
            "607     0.137834  0.118780  0.153063  1.000000  0.283081  0.149190  0.139114  \n",
            "608     0.155306  0.178142  0.262558  0.283081  1.000000  0.121993  0.322055  \n",
            "609     0.236601  0.097610  0.069622  0.149190  0.121993  1.000000  0.053225  \n",
            "610     0.052552  0.119295  0.201104  0.139114  0.322055  0.053225  1.000000  \n",
            "\n",
            "[610 rows x 610 columns]\n"
          ]
        }
      ],
      "source": [
        "# Calculate the cosine similarity matrix for users\n",
        "# Use the utility matrix to compute cosine similarity among users\n",
        "# The resulting matrix has users as both rows and columns, indicating similarity scores between pairs of users\n",
        "cosine_similarity_matrix = pd.DataFrame(\n",
        "    cosine_similarity(utility_matrix),\n",
        "    index=utility_matrix.index,\n",
        "    columns=utility_matrix.index\n",
        ")\n",
        "\n",
        "# Display the user similarity matrix\n",
        "print(cosine_similarity_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-zHysoHwOTM"
      },
      "source": [
        "## Find similar users to our target user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "WM9yeSmIKiMn"
      },
      "outputs": [],
      "source": [
        "def get_users_who_rated_movie(movie_id, utility_matrix):\n",
        "    \"\"\"\n",
        "    Returns a list of users who have rated a specific movie.\n",
        "\n",
        "    Parameters:\n",
        "    - movie_id: the ID of the movie.\n",
        "    - utility_matrix: a user-item matrix (DataFrame) with users as rows, movie IDs as columns, and ratings as values.\n",
        "\n",
        "    Returns:\n",
        "    - A list of user IDs who rated the specified movie.\n",
        "    \"\"\"\n",
        "    # Identify users who have rated the specified movie\n",
        "    rated_users = utility_matrix.index[utility_matrix[movie_id] != 0].tolist()\n",
        "    return rated_users\n",
        "\n",
        "def find_similar_users(target_user_id, rated_users, similarity_matrix, k=3):\n",
        "    \"\"\"\n",
        "    Finds and returns the top k users most similar to the target user based on a similarity matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - target_user_id: the ID of the target user.\n",
        "    - rated_users: a list of users who have rated a specific movie.\n",
        "    - similarity_matrix: a Cosine similarity matrix (DataFrame) representing the similarity scores between users.\n",
        "    - k: the number of similar users to find (default is 3).\n",
        "\n",
        "    Returns:\n",
        "    - A tuple containing two lists: the IDs of the top k similar users and their corresponding similarity scores.\n",
        "    \"\"\"\n",
        "    # Calculate similarity scores between the target user and users who rated the movie\n",
        "    similarities = similarity_matrix.loc[target_user_id, rated_users]\n",
        "\n",
        "    # Identify the top k most similar users\n",
        "    top_similar_users = similarities.nlargest(k)\n",
        "    return top_similar_users.index.tolist(), top_similar_users.values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjcgqVFtwVUN"
      },
      "source": [
        "## Predict rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Q3ptnhXwW5y9"
      },
      "outputs": [],
      "source": [
        "def predict_rating_cosine(df, utility_matrix, similarity_matrix):\n",
        "    \"\"\"\n",
        "    Predicts ratings for a given set of user-movie pairs using cosine similarity.\n",
        "\n",
        "    Parameters:\n",
        "    - df: DataFrame with columns 'userId' and 'movieId'.\n",
        "    - utility_matrix: a user-item matrix (DataFrame) with users as rows, movie IDs as columns, and ratings as values.\n",
        "    - similarity_matrix: a Cosine similarity matrix (DataFrame) representing cosine similarity between users.\n",
        "\n",
        "    Returns:\n",
        "    - DataFrame containing columns 'userId', 'movieId', and 'predicted_rating' with the predicted ratings.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize an empty list to store predicted ratings\n",
        "    predicted_ratings = []\n",
        "\n",
        "    # Iterate over each user-movie pair in the input DataFrame\n",
        "    for user_id, movie_id in df.values:\n",
        "        # Find users who have rated the movie\n",
        "        rated_users = get_users_who_rated_movie(movie_id, utility_matrix)\n",
        "        # Find similar users and their similarity scores\n",
        "        similar_users, similarities = find_similar_users(user_id, rated_users, similarity_matrix)\n",
        "\n",
        "        # Initialize variables for the weighted sum of ratings and sum of weights\n",
        "        ratings_sum = 0\n",
        "        weights_sum = 0\n",
        "\n",
        "        # Calculate the weighted sum of ratings from similar users\n",
        "        for similar_user, similarity in zip(similar_users, similarities):\n",
        "            user_rating = utility_matrix.loc[similar_user, movie_id]\n",
        "            ratings_sum += user_rating * similarity\n",
        "            weights_sum += similarity\n",
        "\n",
        "        # Compute the predicted rating\n",
        "        if weights_sum != 0:\n",
        "            predicted_rating = ratings_sum / weights_sum\n",
        "        else:\n",
        "            # If no similar users, use the average rating for the movie\n",
        "            nonzero_ratings = utility_matrix.loc[utility_matrix[movie_id] != 0, movie_id]\n",
        "            predicted_rating = nonzero_ratings.mean() if len(nonzero_ratings) > 0 else 0\n",
        "\n",
        "        # Append the predicted rating to the list\n",
        "        predicted_ratings.append([user_id, movie_id, predicted_rating])\n",
        "\n",
        "    # Convert the list of predicted ratings into a DataFrame\n",
        "    predicted_ratings_df = pd.DataFrame(predicted_ratings, columns=['userId', 'movieId', 'predicted_rating'])\n",
        "    return predicted_ratings_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2quDu5kzwXa0"
      },
      "source": [
        "## Create prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8Xw3NTUdfK-x"
      },
      "outputs": [],
      "source": [
        "# Prepare dataframe for prediction\n",
        "selected_columns = ratings_valid[['userId', 'movieId']]\n",
        "\n",
        "# Predict ratings using Cosine similarity\n",
        "predicted_ratings = predict_rating_cosine(selected_columns, utility_matrix, cosine_similarity_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZrmHQsCwZK5"
      },
      "source": [
        "## Calculate RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3zzyfobgURw",
        "outputId": "3cc0b058-b38c-4314-f7eb-8c440ee7bc09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE = 0.9961\n"
          ]
        }
      ],
      "source": [
        "# Calculate and display the RMSE for the predicted ratings\n",
        "\n",
        "# Prepare data to calculate RMSE by ratings (actual and predicted)\n",
        "actual_ratings = ratings_valid['rating'].to_numpy()\n",
        "predicted_ratings = predicted_ratings['predicted_rating'].to_numpy()\n",
        "\n",
        "# Compute the RMSE\n",
        "rmse_value = mean_squared_error(actual_ratings, predicted_ratings, squared=False)\n",
        "\n",
        "# Print the RMSE\n",
        "print(f\"RMSE = {rmse_value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8DWfxHsjgog"
      },
      "source": [
        "# Pearson similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBFo_DCdY8go"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRfrwmYVY8gp",
        "outputId": "2b64ac69-65d0-44ef-d0ee-90929911f95e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movieId  1       2       3       4       5       6       7       8       \\\n",
            "userId                                                                    \n",
            "1           4.0     0.0     4.0     0.0     0.0     4.0     0.0     0.0   \n",
            "2           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "3           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "4           0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "5           4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "\n",
            "movieId  9       10      ...  193565  193567  193571  193573  193579  193581  \\\n",
            "userId                   ...                                                   \n",
            "1           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "2           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "3           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "4           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "5           0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "\n",
            "movieId  193583  193585  193587  193609  \n",
            "userId                                   \n",
            "1           0.0     0.0     0.0     0.0  \n",
            "2           0.0     0.0     0.0     0.0  \n",
            "3           0.0     0.0     0.0     0.0  \n",
            "4           0.0     0.0     0.0     0.0  \n",
            "5           0.0     0.0     0.0     0.0  \n",
            "\n",
            "[5 rows x 9690 columns]\n"
          ]
        }
      ],
      "source": [
        "# Construct the user-item matrix from training data\n",
        "# Pivot the training dataset to create a matrix with users as rows, movies as columns, and ratings as values\n",
        "# Fill missing ratings with 0 to indicate unrated movies\n",
        "utility_matrix = ratings_train.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "\n",
        "# Display the first few rows of the utility matrix to verify its structure\n",
        "print(utility_matrix.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzY_bjH9whEu"
      },
      "source": [
        "## Create Pearson Similarity Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX5oLwtfjJQW",
        "outputId": "12c9e827-9bee-4b5a-c12a-3736f82301c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "userId       1         2         3         4         5         6         7    \\\n",
            "userId                                                                         \n",
            "1       1.000000 -0.140122 -0.083659  0.085724 -0.068594 -0.002084 -0.013237   \n",
            "2      -0.140122  1.000000  0.241867 -0.052336  0.065753 -0.061165 -0.094267   \n",
            "3      -0.083659  0.241867  1.000000 -0.016926  0.124382 -0.051919 -0.076738   \n",
            "4       0.085724 -0.052336 -0.016926  1.000000 -0.000493 -0.022182 -0.022595   \n",
            "5      -0.068594  0.065753  0.124382 -0.000493  1.000000  0.194005 -0.071550   \n",
            "...          ...       ...       ...       ...       ...       ...       ...   \n",
            "606     0.025781 -0.151882 -0.149200  0.054609 -0.088802 -0.043876  0.050126   \n",
            "607     0.136872 -0.117103 -0.076055  0.007923 -0.016660  0.040365  0.021911   \n",
            "608     0.134672 -0.244170 -0.247130 -0.024897 -0.169082  0.005041  0.131082   \n",
            "609    -0.120499  0.152168  0.208574 -0.075440  0.249909  0.093092 -0.085606   \n",
            "610    -0.004954 -0.101139 -0.156579 -0.050750 -0.162674 -0.113235  0.030054   \n",
            "\n",
            "userId       8         9         10   ...       601       602       603  \\\n",
            "userId                                ...                                 \n",
            "1      -0.081667 -0.091622 -0.122058  ... -0.099397 -0.008600  0.107905   \n",
            "2       0.022545  0.161707  0.109852  ...  0.083583 -0.093881 -0.127928   \n",
            "3       0.073078  0.226473  0.087951  ... -0.073286 -0.059046 -0.097541   \n",
            "4      -0.070408 -0.040077 -0.043597  ... -0.042260 -0.006656  0.174413   \n",
            "5       0.356603  0.048550 -0.000619  ... -0.114278  0.290692 -0.047813   \n",
            "...          ...       ...       ...  ...       ...       ...       ...   \n",
            "606    -0.111867 -0.094541 -0.060164  ...  0.034889 -0.054208  0.168837   \n",
            "607    -0.004059 -0.108953 -0.111248  ... -0.083691  0.037902  0.084965   \n",
            "608    -0.126499 -0.169281 -0.129798  ... -0.061773 -0.031707  0.074558   \n",
            "609     0.370535  0.121214  0.027597  ... -0.142647  0.186043 -0.112266   \n",
            "610    -0.159102 -0.118350 -0.039563  ...  0.078831 -0.103331 -0.005027   \n",
            "\n",
            "userId       604       605       606       607       608       609       610  \n",
            "userId                                                                        \n",
            "1      -0.084914  0.019171  0.025781  0.136872  0.134672 -0.120499 -0.004954  \n",
            "2       0.017947 -0.048857 -0.151882 -0.117103 -0.244170  0.152168 -0.101139  \n",
            "3       0.067481 -0.001768 -0.149200 -0.076055 -0.247130  0.208574 -0.156579  \n",
            "4      -0.044935 -0.006307  0.054609  0.007923 -0.024897 -0.075440 -0.050750  \n",
            "5       0.209565  0.050482 -0.088802 -0.016660 -0.169082  0.249909 -0.162674  \n",
            "...          ...       ...       ...       ...       ...       ...       ...  \n",
            "606    -0.095281  0.004996  1.000000  0.007012  0.096843 -0.148515  0.022982  \n",
            "607     0.007428 -0.012280  0.007012  1.000000  0.108457 -0.026311 -0.020069  \n",
            "608    -0.069862 -0.014282  0.096843  0.108457  1.000000 -0.222017  0.164090  \n",
            "609     0.208013  0.007612 -0.148515 -0.026311 -0.222017  1.000000 -0.192275  \n",
            "610    -0.127279 -0.041268  0.022982 -0.020069  0.164090 -0.192275  1.000000  \n",
            "\n",
            "[610 rows x 610 columns]\n"
          ]
        }
      ],
      "source": [
        "def pearson_similarity(utility_matrix):\n",
        "    \"\"\"\n",
        "    Computes the Pearson similarity matrix for users based on their ratings.\n",
        "\n",
        "    Parameters:\n",
        "    - utility_matrix: a user-item matrix (DataFrame) with users as rows, movie IDs as columns, and ratings as values.\n",
        "\n",
        "    Returns:\n",
        "    - A matrix (DataFrame) representing the Pearson similarity between users.\n",
        "    \"\"\"\n",
        "\n",
        "    # Transpose the matrix to have movies as rows and users as columns\n",
        "    transposed_matrix = utility_matrix.T\n",
        "\n",
        "    # Center the ratings by subtracting the mean rating for each movie\n",
        "    centered_matrix = transposed_matrix.sub(transposed_matrix.mean(axis=1), axis=0)\n",
        "\n",
        "    # Calculate the Pearson correlation coefficient between users\n",
        "    similarity_matrix = centered_matrix.corr(method='pearson')\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "# Calculate and display the Pearson similarity matrix\n",
        "pearson_similarity_matrix = pearson_similarity(utility_matrix)\n",
        "print(pearson_similarity_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fw4Wijjwk4Q"
      },
      "source": [
        "## Find similar users to our target user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "vx0gAHUblrCk"
      },
      "outputs": [],
      "source": [
        "def get_users_who_rated_movie(movie_id, utility_matrix):\n",
        "    \"\"\"\n",
        "    Returns a list of users who have rated a specific movie.\n",
        "\n",
        "    Parameters:\n",
        "    - movie_id: the ID of the movie to check.\n",
        "    - utility_matrix: a user-item matrix (DataFrame) with users as rows, movie IDs as columns, and ratings as values.\n",
        "\n",
        "    Returns:\n",
        "    - List of user IDs who rated the specified movie.\n",
        "    \"\"\"\n",
        "    # Filter the utility matrix to find users who have rated the movie\n",
        "    rated_users = utility_matrix.index[utility_matrix[movie_id] != 0].tolist()\n",
        "    return rated_users\n",
        "\n",
        "def find_similar_users(target_user_id, rated_users, similarity_matrix, k=10):\n",
        "    \"\"\"\n",
        "    Finds and returns the top k users most similar to the target user.\n",
        "\n",
        "    Parameters:\n",
        "    - target_user_id: the ID of the user for whom to predict ratings.\n",
        "    - rated_users: list of users who have rated a specific movie.\n",
        "    - similarity_matrix: a Pearson similarity matrix (DataFrame) containing similarity scores between users.\n",
        "    - k: number of similar users to find (default is 10).\n",
        "\n",
        "    Returns:\n",
        "    - Tuple of two lists: IDs of the top k similar users and their similarity scores.\n",
        "    \"\"\"\n",
        "    # Calculate similarity scores between the target user and users who rated the movie\n",
        "    similarities = similarity_matrix.loc[target_user_id, rated_users]\n",
        "    # Select the top k most similar users\n",
        "    similar_users = similarities.nlargest(k)\n",
        "    return similar_users.index.tolist(), similar_users.values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg__h9Vnwvta"
      },
      "source": [
        "## Predict rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "jNmAYrmLmD_D"
      },
      "outputs": [],
      "source": [
        "def predict_rating_pearson(df, utility_matrix, similarity_matrix):\n",
        "    \"\"\"\n",
        "    Predicts ratings using Pearson correlation for a given set of user-movie pairs.\n",
        "\n",
        "    Parameters:\n",
        "    - df: DataFrame with columns 'userId' and 'movieId'.\n",
        "    - utility_matrix: a user-item matrix (DataFrame) with users as rows, movie IDs as columns, and ratings as values.\n",
        "    - similarity_matrix: a Pearson similarity matrix (DataFrame) representing Pearson similarity between users.\n",
        "\n",
        "    Returns:\n",
        "    - DataFrame containing 'userId', 'movieId', and 'predicted_rating'.\n",
        "    \"\"\"\n",
        "\n",
        "    predicted_ratings = []\n",
        "\n",
        "    for user_id, movie_id in df.values:\n",
        "        # Find users who have rated the movie and their similarity scores\n",
        "        rated_users = get_users_who_rated_movie(movie_id, utility_matrix)\n",
        "        similar_users, similarities = find_similar_users(user_id, rated_users, similarity_matrix)\n",
        "\n",
        "        # Calculate the average rating of the target user for rated movies\n",
        "        target_user_avg_rating = utility_matrix.loc[user_id][utility_matrix.loc[user_id] != 0].mean()\n",
        "\n",
        "        ratings_sum = 0\n",
        "        weights_sum = 0\n",
        "\n",
        "        for similar_user, similarity in zip(similar_users, similarities):\n",
        "            # Calculate the average rating of the similar user for rated movies\n",
        "            similar_user_avg_rating = utility_matrix.loc[similar_user][utility_matrix.loc[similar_user] != 0].mean()\n",
        "\n",
        "            # Adjust the rating for the target movie by the similar user's average rating\n",
        "            user_rating_adjusted = utility_matrix.at[similar_user, movie_id] - similar_user_avg_rating\n",
        "\n",
        "            ratings_sum += user_rating_adjusted * similarity\n",
        "            weights_sum += abs(similarity)\n",
        "\n",
        "        # Calculate the predicted rating\n",
        "        if weights_sum != 0:\n",
        "            predicted_rating = target_user_avg_rating + (ratings_sum / weights_sum)\n",
        "        else:\n",
        "            # Use the target user's average rating if no similar users found\n",
        "            predicted_rating = target_user_avg_rating\n",
        "\n",
        "        predicted_ratings.append([user_id, movie_id, predicted_rating])\n",
        "\n",
        "    return pd.DataFrame(predicted_ratings, columns=['userId', 'movieId', 'predicted_rating'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stqcxFC7wx2P"
      },
      "source": [
        "## Create prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2iu_bJQztjn_"
      },
      "outputs": [],
      "source": [
        "# Prepare dataframe for prediction\n",
        "selected_columns = ratings_valid[['userId', 'movieId']]\n",
        "\n",
        "# Predict ratings using Pearson correlation\n",
        "predicted_ratings = predict_rating_pearson(selected_columns, utility_matrix, pearson_similarity_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79bunIiAw21F"
      },
      "source": [
        "## Calculate RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhszsSI6tp9k",
        "outputId": "18915279-8c70-4926-af8a-84ed3bd9eb19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE = 0.8901\n"
          ]
        }
      ],
      "source": [
        "# Calculate and display the RMSE for the predicted ratings\n",
        "\n",
        "# Prepare data to calculate RMSE by ratings (actual and predicted)\n",
        "actual_ratings = ratings_valid['rating'].to_numpy()\n",
        "predicted_ratings = predicted_ratings['predicted_rating'].to_numpy()\n",
        "\n",
        "# Compute the RMSE\n",
        "rmse_value = mean_squared_error(actual_ratings, predicted_ratings, squared=False)\n",
        "\n",
        "# Print the RMSE\n",
        "print(f\"RMSE = {rmse_value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G96DyKyU2YPr"
      },
      "source": [
        "# Latent factor model with biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyDsz68KY8gr"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ZKI8uIeqY8gr"
      },
      "outputs": [],
      "source": [
        "# Number of latent factors to use in matrix factorization\n",
        "num_latent_factors = 20\n",
        "\n",
        "# Learning rate: Determines the step size at each iteration while moving toward a minimum of the loss function.\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Epochs: Number of complete passes through the training dataset.\n",
        "epochs = 30\n",
        "\n",
        "# Regularization parameter: Controls the magnitude of the regularization term added to the loss function to prevent overfitting.\n",
        "reg_param = 0.03"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8F3W3C3w7bl"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "alzBGhcp2agd"
      },
      "outputs": [],
      "source": [
        "# Count unique users and movies\n",
        "num_users = ratings_train['userId'].nunique()\n",
        "num_movies = ratings_train['movieId'].nunique()\n",
        "\n",
        "# Create user-item matrix (users as rows, movies as columns, ratings as values)\n",
        "user_item_matrix = ratings_train.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "\n",
        "# Perform Singular Value Decomposition (SVD) on the user-item matrix\n",
        "U, sigma, Vt = np.linalg.svd(user_item_matrix)\n",
        "\n",
        "# Initialize user and movie factor matrices using the first 'num_latent_factors' components of SVD\n",
        "user_factor_matrix = U[:, :num_latent_factors]\n",
        "movie_factor_matrix = Vt.T[:, :num_latent_factors]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0mCH2GDw_82"
      },
      "source": [
        "## Defining the MSE for training losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "AkmUwWp52xRN"
      },
      "outputs": [],
      "source": [
        "def mse_loss(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"\n",
        "    Calculates the mean squared error between actual and predicted ratings.\n",
        "\n",
        "    Args:\n",
        "        actual: array of actual ratings.\n",
        "        predicted: array of predicted ratings.\n",
        "\n",
        "    Returns:\n",
        "        The mean squared error.\n",
        "    \"\"\"\n",
        "    return np.mean(np.square(actual - predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbL64rurY8gr"
      },
      "source": [
        "## Mapping of data and defining biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "FLiPo24Ckugj"
      },
      "outputs": [],
      "source": [
        "# Create mappings for userId and movieId to indices\n",
        "userId_to_index = {userId: idx for idx, userId in enumerate(ratings_train['userId'].unique())}\n",
        "movieId_to_index = {movieId: idx for idx, movieId in enumerate(ratings_train['movieId'].unique())}\n",
        "\n",
        "# Calculate global bias (average of all ratings)\n",
        "global_avg = ratings_train['rating'].mean()\n",
        "\n",
        "# Calculate user biases (average rating given by each user)\n",
        "user_avg = ratings_train.groupby('userId')['rating'].mean().to_dict()\n",
        "\n",
        "# Calculate item biases (average rating received by each movie)\n",
        "item_avg = ratings_train.groupby('movieId')['rating'].mean().to_dict()\n",
        "\n",
        "def calculate_user_biases(user_avg, userId_to_index, global_avg, num_users):\n",
        "    \"\"\"\n",
        "    Calculates user biases and stores them in an array.\n",
        "\n",
        "    Args:\n",
        "        user_avg: dictionary mapping user IDs to their average ratings.\n",
        "        userId_to_index: dictionary mapping user IDs to their indices.\n",
        "        global_bias: the global average rating.\n",
        "        num_users: the total number of users.\n",
        "\n",
        "    Returns:\n",
        "        An array of user biases.\n",
        "    \"\"\"\n",
        "    user_bias = np.zeros(num_users)\n",
        "    for user_id, rating_mean in user_avg.items():\n",
        "        user_index = userId_to_index[user_id]\n",
        "        user_bias[user_index] = rating_mean - global_avg\n",
        "    return user_bias\n",
        "\n",
        "def calculate_item_biases(item_avg, movieId_to_index, global_avg, num_movies):\n",
        "    \"\"\"\n",
        "    Calculates item biases and stores them in an array.\n",
        "\n",
        "    Args:\n",
        "        item_avg: dictionary mapping movie IDs to their average ratings.\n",
        "        movieId_to_index: dictionary mapping movie IDs to their indices.\n",
        "        global_bias: the global average rating.\n",
        "        num_movies: the total number of movies.\n",
        "\n",
        "    Returns:\n",
        "        An array of item biases.\n",
        "    \"\"\"\n",
        "    item_bias = np.zeros(num_movies)\n",
        "    for movie_id, rating_mean in item_avg.items():\n",
        "        movie_index = movieId_to_index[movie_id]\n",
        "        item_bias[movie_index] = rating_mean - global_avg\n",
        "    return item_bias\n",
        "\n",
        "# Getting the bias arrays\n",
        "user_bias_array = calculate_user_biases(user_avg, userId_to_index, global_avg, num_users)\n",
        "item_bias_array = calculate_item_biases(item_avg, movieId_to_index, global_avg, num_movies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsX4Ib9ZxE6c"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2rTQym8Y8gx",
        "outputId": "d095dda8-9781-42a0-e0f0-580325ebbe5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Training Loss: 0.6301272789352836\n",
            "Epoch 2/30, Training Loss: 0.6302706114172105\n",
            "Epoch 3/30, Training Loss: 0.6304131844276031\n",
            "Epoch 4/30, Training Loss: 0.6305549222351047\n",
            "Epoch 5/30, Training Loss: 0.6306957583999488\n",
            "Epoch 6/30, Training Loss: 0.6308356339485063\n",
            "Epoch 7/30, Training Loss: 0.6309744959566218\n",
            "Epoch 8/30, Training Loss: 0.6311122964763516\n",
            "Epoch 9/30, Training Loss: 0.6312489917427326\n",
            "Epoch 10/30, Training Loss: 0.6313845416019068\n",
            "Epoch 11/30, Training Loss: 0.6315189091084851\n",
            "Epoch 12/30, Training Loss: 0.6316520602477182\n",
            "Epoch 13/30, Training Loss: 0.6317839637460658\n",
            "Epoch 14/30, Training Loss: 0.6319145909415255\n",
            "Epoch 15/30, Training Loss: 0.632043915692145\n",
            "Epoch 16/30, Training Loss: 0.6321719143071703\n",
            "Epoch 17/30, Training Loss: 0.6322985654901978\n",
            "Epoch 18/30, Training Loss: 0.6324238502874733\n",
            "Epoch 19/30, Training Loss: 0.6325477520372275\n",
            "Epoch 20/30, Training Loss: 0.6326702563178271\n",
            "Epoch 21/30, Training Loss: 0.6327913508937169\n",
            "Epoch 22/30, Training Loss: 0.6329110256588256\n",
            "Epoch 23/30, Training Loss: 0.6330292725774536\n",
            "Epoch 24/30, Training Loss: 0.6331460856227927\n",
            "Epoch 25/30, Training Loss: 0.6332614607132339\n",
            "Epoch 26/30, Training Loss: 0.6333753956465825\n",
            "Epoch 27/30, Training Loss: 0.6334878900322497\n",
            "Epoch 28/30, Training Loss: 0.6335989452214479\n",
            "Epoch 29/30, Training Loss: 0.6337085642354214\n",
            "Epoch 30/30, Training Loss: 0.6338167516917521\n"
          ]
        }
      ],
      "source": [
        "def update_biases_and_factors(\n",
        "        user_index,\n",
        "        item_index,\n",
        "        actual_rating,\n",
        "        global_bias,\n",
        "        user_bias_array,\n",
        "        item_bias_array,\n",
        "        user_factor_matrix,\n",
        "        item_factor_matrix,\n",
        "        learning_rate,\n",
        "        regularization):\n",
        "    \"\"\"\n",
        "    Updates the biases and factor matrices for a single user-item interaction.\n",
        "\n",
        "    Args:\n",
        "    - user_index: index of the user.\n",
        "    - item_index: index of the item.\n",
        "    - actual_rating: actual rating given by the user to the item.\n",
        "    - global_bias: global bias across all ratings.\n",
        "    - user_biases: array of user biases.\n",
        "    - item_biases: array of item biases.\n",
        "    - user_factors: user factor matrix.\n",
        "    - item_factors: item factor matrix.\n",
        "    - learning_rate: learning rate for optimization.\n",
        "    - regularization: regularization parameter.\n",
        "\n",
        "    Returns:\n",
        "    Updated user_biases, item_biases, user_factors, item_factors.\n",
        "    \"\"\"\n",
        "    # Calculate the predicted rating\n",
        "    predicted_rating = global_bias + user_bias_array[user_index] + item_bias_array[item_index] + np.dot(user_factor_matrix[user_index], item_factor_matrix[item_index])\n",
        "\n",
        "    # Calculate the error between the actual and predicted rating\n",
        "    error = actual_rating - predicted_rating\n",
        "\n",
        "    # Update user and item biases\n",
        "    user_bias_array[user_index] += learning_rate * (error - regularization * user_bias_array[user_index])\n",
        "    item_bias_array[item_index] += learning_rate * (error - regularization * item_bias_array[item_index])\n",
        "\n",
        "    # Update user and item factor matrices\n",
        "    user_factor_matrix[user_index] += learning_rate * (error * item_factor_matrix[item_index] - regularization * user_factor_matrix[user_index])\n",
        "    item_factor_matrix[item_index] += learning_rate * (error * user_factor_matrix[user_index] - regularization * item_factor_matrix[item_index])\n",
        "\n",
        "    return user_bias_array, item_bias_array, user_factor_matrix, item_factor_matrix\n",
        "\n",
        "def train_model(\n",
        "        ratings_train,\n",
        "        num_epochs,\n",
        "        global_bias,\n",
        "        user_bias_array,\n",
        "        item_bias_array,\n",
        "        user_factor_matrix,\n",
        "        item_factor_matrix,\n",
        "        learning_rate,\n",
        "        regularization):\n",
        "    \"\"\"\n",
        "    Trains the model over a specified number of epochs.\n",
        "\n",
        "    Args:\n",
        "    - ratings: training dataset containing user IDs, item IDs, and ratings.\n",
        "    - num_epochs: number of epochs to train for.\n",
        "    - global_bias: global bias across all ratings.\n",
        "    - user_bias_array: initial array of user biases.\n",
        "    - item_bias_array: initial array of item biases.\n",
        "    - user_factors: initial user factor matrix.\n",
        "    - item_factors: initial item factor matrix.\n",
        "    - learning_rate: learning rate for optimization.\n",
        "    - regularization: regularization parameter.\n",
        "\n",
        "    Returns:\n",
        "    The updated user_biases, item_biases, user_factors, item_factors after training.\n",
        "    \"\"\"\n",
        "    for epoch in range(num_epochs):\n",
        "        for _, row in ratings_train.iterrows():\n",
        "            user_id, item_id, rating = row['userId'], row['movieId'], row['rating']\n",
        "            user_index, item_index = userId_to_index[user_id], movieId_to_index[item_id]\n",
        "\n",
        "            # Update biases and factors for each rating\n",
        "            updated_user_biases, updated_item_biases, updated_user_factors, updated_item_factors = update_biases_and_factors(\n",
        "                user_index,\n",
        "                item_index,\n",
        "                rating,\n",
        "                global_bias,\n",
        "                user_bias_array,\n",
        "                item_bias_array,\n",
        "                user_factor_matrix,\n",
        "                item_factor_matrix,\n",
        "                learning_rate,\n",
        "                regularization)\n",
        "\n",
        "        # Calculate predicted ratings using the updated biases and factors on each epoch\n",
        "        predicted_ratings = global_avg + updated_user_biases[:, np.newaxis] + updated_item_biases[np.newaxis, :] + np.dot(P, Q.T)\n",
        "\n",
        "        # Calculate the training loss (MSE) on each epoch\n",
        "        train_loss = mse_loss(ratings_train['rating'], predicted_ratings[ratings_train['userId'].map(userId_to_index), ratings_train['movieId'].map(movieId_to_index)])\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {train_loss}\")\n",
        "\n",
        "    return updated_user_biases, updated_item_biases, updated_user_factors, updated_item_factors\n",
        "\n",
        "# Call the train_model function to train the model and get the updated biases and factors\n",
        "updated_user_bias_array, updated_item_bias_array, updated_user_factors, updated_item_factors = train_model(\n",
        "    ratings_train,\n",
        "    epochs,\n",
        "    global_avg,\n",
        "    user_bias_array,\n",
        "    item_bias_array,\n",
        "    user_factor_matrix,\n",
        "    movie_factor_matrix,\n",
        "    learning_rate,\n",
        "    reg_param)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czliDIVqxIZp"
      },
      "source": [
        "## Predict Rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "IhJeRIUIY8gy"
      },
      "outputs": [],
      "source": [
        "def predict_ratings(\n",
        "    user_item_pairs,\n",
        "    user_to_index_map,\n",
        "    item_to_index_map,\n",
        "    global_average,\n",
        "    updated_user_bias_array,\n",
        "    updated_item_bias_array,\n",
        "    updated_user_factors,\n",
        "    updated_item_factors):\n",
        "    \"\"\"\n",
        "    Predicts ratings for given user-item pairs.\n",
        "\n",
        "    Args:\n",
        "    - user_item_pairs: DataFrame with columns ['userId', 'movieId'] representing user-item pairs.\n",
        "    - user_to_index_map: mapping from user IDs to their corresponding index in the bias and factor arrays.\n",
        "    - item_to_index_map: mapping from item IDs (movie IDs) to their corresponding index in the bias and factor arrays.\n",
        "    - global_average: global average rating across all users and items.\n",
        "    - user_bias_array: array of user-specific bias values.\n",
        "    - item_bias_array: array of item-specific bias values.\n",
        "    - user_factors: matrix of user-specific factors.\n",
        "    - item_factors: matrix of item-specific factors.\n",
        "\n",
        "    Returns:\n",
        "    DataFrame: A DataFrame with columns ['userId', 'movieId', 'predicted_rating'] containing the predicted ratings.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "\n",
        "    # Iterate over each user-item pair\n",
        "    for user_id, movie_id in user_item_pairs.values:\n",
        "        # Map user and item to their respective indices\n",
        "        user_index = user_to_index_map[user_id]\n",
        "        item_index = item_to_index_map[movie_id]\n",
        "\n",
        "        # Calculate the predicted rating\n",
        "        predicted_rating = (\n",
        "            global_average +\n",
        "            updated_user_bias_array[user_index] +\n",
        "            updated_item_bias_array[item_index] +\n",
        "            np.dot(updated_user_factors[user_index], updated_item_factors[item_index])\n",
        "        )\n",
        "\n",
        "        # Append the prediction to the list\n",
        "        predictions.append({\n",
        "            'userId': user_id,\n",
        "            'movieId': movie_id,\n",
        "            'predicted_rating': predicted_rating\n",
        "        })\n",
        "\n",
        "    # Convert the list of predictions to a DataFrame\n",
        "    predicted_ratings_df = pd.DataFrame(predictions)\n",
        "\n",
        "    return predicted_ratings_df\n",
        "\n",
        "# Prepare DataFrame for prediction\n",
        "selected_columns = ratings_valid[['userId', 'movieId']]\n",
        "\n",
        "# Predict ratings\n",
        "predicted_ratings_df = predict_ratings(\n",
        "    selected_columns,\n",
        "    userId_to_index,\n",
        "    movieId_to_index,\n",
        "    global_avg,\n",
        "    updated_user_bias_array,\n",
        "    updated_item_bias_array,\n",
        "    user_factor_matrix,\n",
        "    movie_factor_matrix\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU_MQqIGY8gy"
      },
      "source": [
        "## Calculate RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bel3PFZSY8gy",
        "outputId": "8ac35a21-1640-4541-e4ab-a2174f08ed65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE = 0.8341\n"
          ]
        }
      ],
      "source": [
        "# Calculate the Root Mean Square Error (RMSE) between actual and predicted ratings\n",
        "actual_ratings = ratings_valid['rating'].to_numpy()\n",
        "predicted_ratings = predicted_ratings_df['predicted_rating'].to_numpy()\n",
        "\n",
        "# Compute RMSE\n",
        "rmse = mean_squared_error(actual_ratings, predicted_ratings, squared=False)\n",
        "\n",
        "# Display the RMSE result\n",
        "print(f\"RMSE = {rmse:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}